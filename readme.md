## üÇ° Rust Poker

### Summary

I made this because I wanted to learn about Rust, and about how Poker is being solved. This project isn't complete, and will perform poorly (can be easily exploited) in turn and river rounds, but plays very sensibly pre-flop and on the flop.

### Project Overview

I developed this project over the 2024/25 winter holidays with the goal of familiarising myself with both Rust and techniques for solving poker variants. In particular, I focused on approximating a Nash Equilibrium strategy for Heads-Up (2-player) Limit Texas Hold'Em (a variant with capped and fixed bet sizes).

Limit Hold'Em was an appealing choice because it simplifies certain aspects of the game and significantly reduces the decision tree size‚Äîabout 10¬π¬≥ decision points versus 10¬π‚Å∂¬π in No-Limit Heads-Up poker ([source](https://www.science.org/doi/10.1126/science.aao1733)). This allowed me to train the model in roughly an hour on a 12-core laptop with 16 GB of RAM.

On the Rust side, my aim was to learn the language fundamentals: structs, traits, the borrow checker, pattern matching, modules, and crates. I also explored Rust‚Äôs excellent ecosystem and tooling, including `Clippy`, `itertools`, and `rstest`.

From a poker AI perspective, I explored Monte Carlo Counterfactual Regret Minimisation (MCCFR), and studied how modern bots build coarse models via self-play and refine them using techniques like Max-Margin subgame solving. I've implemented many of these techniques (with subgame solving still in progress), and gained insight into the impressive abstractions, optimizations, and clever heuristics developed over the past few decades to make such problems tractable.

Along the way, I picked up numerous low-level optimizations for computation trees, including bit-level tricks for fast calculations, and developed a foundational understanding of some statistical concepts. I also made an effort to write clean, well-tested, and reasonably idiomatic Rust‚Äîwhile there's still room for improvement, I'm generally happy with the results.

### üìãProject components check-list: 

- [x] Core primitives and models: Implement card representations, player structures, action enums, and general utility functions.

- [x] Hand evaluation: Build a fast and accurate evaluator for ranking hands at showdown, based on the 7,462 distinct poker hand classes.

- [x] Game state management: Develop logic for tracking and updating the state of the game during training and evaluation.

- [x] Strategy hub: Create a central system for distributing hand-pairings during each iteration, with serialization/deserialization for persistence.

- [x] Multi-threaded MCCFR trainer: Implement the core recursive traversal logic, with regret tracking across threads to accelerate training.

- [x] Game abstraction layer: Introduce abstractions for reducing and grouping similar branches of the game tree to lower computational costs.

- [ ] Max-Margin subgame solver: Work toward a solver to improve Nash Equilibrium approximations in later betting rounds (in progress).

- [ ] Evaluation: Measure model strength in terms of performance metrics like milli-big blinds per 1,000 hands, both at play and runtime. Also performance benchmarks, memory profiling.

- [ ] User interface: Develop a minimal interface‚ÄîCLI or lightweight GUI‚Äîfor users to play against the bot or evaluate specific positions.

- [ ] Containerisation and hosting: Package the application for deployment, and set it up for cloud hosting or remote access.

### üöÄ How to Run the Program

- **Set the thread count**  
  Configure the number of threads in `config.rs`. Ensure it does **not** exceed the number of physical or logical cores available on your system to avoid performance issues.

- **Train the strategy**
  ```
  cargo run --release -- train
  ```
  
  This will run the MCCFR training loop (default ~30 minutes) and output the generated strategy to the `./blueprint` directory.

  To shorten training time, reduce the `TRAIN_ITERATIONS` constant in the config.

- **Validate the strategy**

  ```
  cargo run --release -- validate
  ```

  This command loads the generated strategy and prints the opening action chart for the small blind (first-to-act) player.


### Example strategy

To contextualise things, this is what the pre-flop strategy looks like for the small blind (SB) action of the game, with offsuit (o) hands. The action so far is `call` for the small-blind, then `raise` by the `big-blind`. As you can see, we fold two+seven hands (the worst poker hand), call hands like four-five, or five-ten some percentage of the time, and always raise with pocket aces.

```
Validating...
Deserialising strategy hub from ./blueprint/
Successfully deserialised strategy hub with 338 elements (compressed size 403 MB, uncompressed size 1037 MB)
Strategies for the preflop small blind, facing big-blind raise
27oSB: strat Check/Fold 100.0%, Call 0.0%, Bet 0.0%
45oSB: strat Check/Fold 0.0%, Call 49.6%, Bet 50.4%
5ToSB: strat Check/Fold 0.0%, Call 57.7%, Bet 42.3%
AAoSB: strat Check/Fold 0.0%, Call 0.0%, Bet 100.0%
```

### üìñSources and brief explanation.

Here's a quick list of some of the research I foudn most useful. MCCFR I feel is best described in [1]. In terms of a Pseudo-implementation of MCCFR, algorithm 1 of [8] is excellent, and there are a few reasonably well explained code explanations out there also [9].

While attempting subgame solving, I've used the ideas from [3] to improve performance of 'best response' calculations - massively improves speed while not changing the underlying problem being solved.

The end goal architecture was to have a simplified form of Libratus [4] (but for 'limit' poker), using the blueprint strategy for flop and pre-flop, and then solving subgames in the last betting rounds. Like Libratus I also used discount CFR [2]. Unlike Libratus I used regular max-margin subgame solving [5], not the improved reach margin form [6] as the former is a stepping stone to the slightly more complex latter implementation.

Finally I copied [7] for my hand-evaulator, and opted for a (large) pre-allocated array, rather than a binary search for a small speed improvement in hand-evaluation.

_____________

[1] M. Lanctot, K. Waugh, M. Zinkevich, and M. Bowling, ‚ÄúMonte Carlo Sampling for Regret Minimization in Extensive Games.‚Äù Accessed: May 26, 2025. [Online]. Available: https://mlanctot.info/files/papers/nips09mccfr.pdf

[2] N. Brown and T. Sandholm, ‚ÄúSolving Imperfect-Information Games via Discounted Regret Minimization,‚Äù Proceedings of the AAAI Conference on Artificial Intelligence, vol. 33, pp. 1829‚Äì1836, Jul. 2019, doi: https://doi.org/10.1609/aaai.v33i01.33011829.

[3] M. Johanson, K. Waugh, M. Bowling, and M. Zinkevich, ‚ÄúAccelerating Best Response Calculation in Large Extensive Games,‚Äù 2011. Accessed: May 26, 2025. [Online]. Available: https://martin.zinkevich.org/publications/ijcai2011_rgbr.pdf

[4] N. Brown and T. Sandholm, ‚ÄúSuperhuman AI for heads-up no-limit poker: Libratus beats top professionals,‚Äù Science, vol. 359, no. 6374, pp. 418‚Äì424, Dec. 2017, doi: https://doi.org/10.1126/science.aao1733.

[5] Matej Moravƒç√≠k, M. Schmid, K. Ha, M. Hlad√≠k, and S. Gaukrodger, ‚ÄúRefining Subgames in Large Imperfect Information Games,‚Äù Proceedings of the ... AAAI Conference on Artificial Intelligence, vol. 30, no. 1, Feb. 2016, doi: https://doi.org/10.1609/aaai.v30i1.10033.

[6] N. Brown and T. Sandholm, ‚ÄúSafe and Nested Subgame Solving for Imperfect-Information Games,‚Äù Neural Information Processing Systems, vol. 30, pp. 689‚Äì699, Jan. 2017.

[7]‚ÄØK. Suffecool, "Cactus Kev's Poker Hand Evaluator," suffe.cool, [Online]. Available: https://suffe.cool/poker/evaluator.html. [Accessed: 26-May-2025].

[8] T. Neller and M. Lanctot, ‚ÄúAn Introduction to Counterfactual Regret Minimization 1 Motivation,‚Äù 2013. Available: https://www.ma.imperial.ac.uk/~dturaev/neller-lanctot.pdf

[9] ‚ÄúRegret Minimization in Games with Incomplete Information (CFR),‚Äù Regret Minimization in Games with Incomplete Information (CFR), 2025. https://nn.labml.ai/cfr/index.html#HistoryProbability (accessed May 26, 2025).

_____


A couple of interesting GitHub projects I saw. The implementation was quite different despite the data structures being the same:

* [Slumbot2019 CFR](https://github.com/ericgjackson/slumbot2019)

* [RoboPoker](https://github.com/krukah/robopoker)

* [PyCFR](https://github.com/tansey/pycfr)